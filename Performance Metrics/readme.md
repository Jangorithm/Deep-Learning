Performance Metrics 성능지표
딥러닝 모델의 성능을 평가하는 다양한 지표는 모델이 얼마나 잘 예측하는지, 어느 부분에서 실수를 하고 있는지를 파악하는 데 도움

### 성능 평가 지표 (Performance Evaluation Metrics)

#### 1. **정확도 (Accuracy)**
**정의:** 전체 예측 중에서 올바르게 예측된 샘플의 비율을 의미합니다.

**공식:** 
\[ \text{정확도} = \frac{\text{정확한 예측 수}}{\text{전체 예측 수}} \]

**한계:** 데이터의 클래스 불균형 문제에서는 부적절할 수 있습니다. 예를 들어, 데이터의 90%가 하나의 클래스에 속하는 경우, 단순히 그 클래스로 예측하는 것만으로도 높은 정확도를 얻을 수 있습니다.

#### 2. **정밀도 (Precision)**
**정의:** 양성으로 예측한 것 중에서 실제로 양성인 샘플의 비율을 의미합니다.

**공식:** 
\[ \text{정밀도} = \frac{\text{참 양성}}{\text{참 양성} + \text{거짓 양성}} \]

**용도:** 오탐지(False Positive)가 중요한 경우, 예를 들어 이메일 스팸 필터링에서 스팸 메일을 일반 메일로 잘못 분류하는 것을 줄이는 데 유용합니다.

#### 3. **재현율 (Recall) / 민감도 (Sensitivity)**
**정의:** 실제 양성 중에서 모델이 양성으로 올바르게 예측한 비율을 의미합니다.

**공식:** 
\[ \text{재현율} = \frac{\text{참 양성}}{\text{참 양성} + \text{거짓 음성}} \]

**용도:** 음성으로 잘못 예측하는 것(False Negative)을 줄이는 데 중점을 두는 경우 유용합니다. 예를 들어, 질병 진단에서 환자를 놓치지 않기 위해 높은 재현율이 필요합니다.

#### 4. **F1 점수 (F1 Score)**
**정의:** 정밀도와 재현율의 조화 평균으로, 두 지표 간의 균형을 평가합니다.

**공식:** 
\[ \text{F1 점수} = 2 \times \frac{\text{정밀도} \times \text{재현율}}{\text{정밀도} + \text{재현율}} \]

**용도:** 정밀도와 재현율 중 어느 하나에 치우치지 않고 균형 잡힌 성능을 원할 때 유용합니다.

#### 5. **ROC 곡선 (Receiver Operating Characteristic Curve) 및 AUC (Area Under the Curve)**
**정의:** ROC 곡선은 참 양성 비율(TPR, True Positive Rate)과 거짓 양성 비율(FPR, False Positive Rate)을 시각화한 그래프입니다. AUC는 이 곡선 아래의 면적을 의미하며, 모델의 성능을 평가합니다.

**공식:** 
\[ \text{TPR} = \frac{\text{참 양성}}{\text{참 양성} + \text{거짓 음성}} \]
\[ \text{FPR} = \frac{\text{거짓 양성}}{\text{거짓 양성} + \text{참 음성}} \]

**용도:** 이진 분류 문제에서 모델의 전체 성능을 평가할 때 유용합니다. AUC 값이 1에 가까울수록 성능이 좋습니다.

#### 6. **혼동 행렬 (Confusion Matrix)**
**정의:** 모델의 예측 결과를 실제 클래스와 비교하여 시각화한 행렬입니다. 4개의 주요 값으로 구성됩니다: 참 양성 (TP), 참 음성 (TN), 거짓 양성 (FP), 거짓 음성 (FN).

**구성:**
- **참 양성 (True Positive, TP):** 실제 양성이고 양성으로 예측한 경우
- **참 음성 (True Negative, TN):** 실제 음성이고 음성으로 예측한 경우
- **거짓 양성 (False Positive, FP):** 실제는 음성인데 양성으로 예측한 경우
- **거짓 음성 (False Negative, FN):** 실제는 양성인데 음성으로 예측한 경우

**용도:** 모델이 어떤 유형의 오류를 많이 저지르는지 분석하는 데 유용합니다.


#### 7. **특이도 (Specificity)**
**정의:** 실제 음성 중에서 모델이 음성으로 올바르게 예측한 비율을 의미합니다.

**공식:** 
\[ \text{특이도} = \frac{\text{참 음성}}{\text{참 음성} + \text{거짓 양성}} \]

**용도:** 오탐지(False Positive)를 줄이는 데 유용합니다. 예를 들어, 암 검진에서 음성을 정확히 판별하는 것이 중요합니다.

#### 8. **정밀도-재현율 곡선 (Precision-Recall Curve)**
**정의:** 정밀도와 재현율의 관계를 시각화한 그래프로, 특히 데이터 클래스 불균형이 심한 경우 유용합니다.

**용도:** 다양한 임계값에서 모델의 성능을 평가할 때 사용됩니다.

#### 9. **F2 점수 (F2 Score)**
**정의:** 재현율을 정밀도보다 더 강조하는 지표입니다. F1 점수가 정밀도와 재현율을 동등하게 고려하는 것과 달리, F2 점수는 재현율의 중요성을 더 강조합니다.

**공식:** 
\[ \text{F2 점수} = 5 \times \frac{\text{정밀도} \times \text{재현율}}{4 \times \text{정밀도} + \text{재현율}} \]

#### 10. **매크로 평균 및 마이크로 평균 (Macro Average and Micro Average)**
**정의:** 다중 클래스 분류에서 성능 지표의 평균을 계산하는 방법입니다.

- **매크로 평균 (Macro Average):** 각 클래스의 성능 지표를 계산한 후, 평균을 구하는 방법으로 클래스의 크기와 관계없이 각 클래스에 동일한 가중치를 부여합니다.
  
- **마이크로 평균 (Micro Average):** 모든 클래스의 참 양성, 거짓 양성, 거짓 음성 값을 합산한 후 성능 지표를 계산하는 방법으로 클래스의 크기에 따라 가중치를 부여합니다.
